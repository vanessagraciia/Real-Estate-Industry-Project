{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by defining the desired data to extract from the immense ABS datasets. If we didn't do this our data frames and outputs later would become hard to read and overload the computer.\n",
    "\n",
    "Note that these features were chosen after sifitng through several ABS datasets in excel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SA2 Area Name'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wanted_descriptors= [\n",
    "    'Estimated resident population (no.)',\n",
    "    'Population density (persons/km2)',\n",
    "    'Median age - persons (years)',\n",
    "    'Working age population (aged 15-64 years) (no.)',\n",
    "    'Employed (no.)', 'Unemployed (no.)', 'Renter (no.)',\n",
    "    'Health care and social assistance (no.)','Financial and insurance services (no.)',\n",
    "    'Administrative and support services (no.)','Education and training (no.)',\n",
    "    'Accommodation and food services (no.)','Public administration and safety (no.)',\n",
    "    'Value of residential building ($m)', 'Houses - total (no.)', \n",
    "    'Townhouses - total (no.)', 'Apartments - total (no.)',\n",
    "    'Median weekly household rental payment ($)', 'Rented (no.)',\n",
    "    'Count of homeless persons (no.)','Used at least one form of public transport (train, tram, bus, ferry) (no.)', \n",
    "    'Median equivalised total household income (weekly) ($)'\n",
    "]\n",
    "\n",
    "\n",
    "#Construct the three dataframes that will be used to store the information from each respective year\n",
    "wanted_descriptors.append('SA2 Area Name')\n",
    "SA2_df_2020 = pd.DataFrame(columns= wanted_descriptors)\n",
    "SA2_df_2021 = pd.DataFrame(columns= wanted_descriptors)\n",
    "SA2_df_2022 = pd.DataFrame(columns= wanted_descriptors)\n",
    "\n",
    "#Remove SA2 name for later\n",
    "wanted_descriptors.pop()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ABS_df_get(year, df):\n",
    "    '''This fucntion will take the year we want to build the dataframe for and the \n",
    "       corresponding dataframe from the previous segment and fill each row with a specific\n",
    "       areas information from that year.'''\n",
    "    \n",
    "    for dir in os.listdir('../data/raw/ABS SA2 Inner Melbourne'):\n",
    "        curr_df = pd.read_csv('../data/raw/ABS SA2 Inner Melbourne/'+dir)\n",
    "\n",
    "        \n",
    "        #Build an indecies list that will have the row number of the wanted descriptor from our list\n",
    "        indecies = []\n",
    "        for i in range(len(wanted_descriptors)):\n",
    "            indecies.append(None) \n",
    "\n",
    "\n",
    "        #Since not all ABS csv's are the same, we need to find what row number our wanted information is and save it\n",
    "        count = 0\n",
    "        for descriptor in wanted_descriptors:\n",
    "            try:\n",
    "                r = curr_df.index[curr_df['Description'] == descriptor].to_list()[0] \n",
    "                indecies[count] = r\n",
    "                count+=1\n",
    "            except:\n",
    "                indecies[count] = None\n",
    "                count+=1\n",
    "        \n",
    "\n",
    "        #for the new row in the dataframe fill it with the information form the ABS data\n",
    "        new_row = []\n",
    "        for i in indecies:\n",
    "            try:\n",
    "                new_row.append(curr_df[year][i])\n",
    "            except:\n",
    "                new_row.append(None)\n",
    "\n",
    "\n",
    "        new_row.append(dir)\n",
    "\n",
    "        df.loc[len(df)] = new_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just retirve and save our data for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ABS_df_get('2020', SA2_df_2020)\n",
    "ABS_df_get('2021', SA2_df_2021)\n",
    "ABS_df_get('2022', SA2_df_2022)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA2_df_2020.to_csv(os.path.join('../data/curated','2020ABS_csv'))\n",
    "SA2_df_2021.to_csv(os.path.join('../data/curated','2021ABS_csv'))\n",
    "SA2_df_2022.to_csv(os.path.join('../data/curated','2022ABS_csv'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
